{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、项目背景介绍\n",
    "\n",
    "对男生来说，区分女生化妆品很累吧，瓶瓶盘盘的有一堆的，利用迁移学习的方法来训练这些数据。\n",
    "\n",
    "随着越来越多的机器学习应用场景的出现，而现有表现比较好的监督学习需要大量的标注数据，标注数据是一项枯燥无味且花费巨大的任务，所以迁移学习受到越来越多的关注。\n",
    "\n",
    "迁移学习是一种机器学习方法，就是把为任务 A 开发的模型作为初始点，重新使用在为任务 B 开发模型的过程中。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二、数据介绍\n",
    "\n",
    "化妆品分类  https://aistudio.baidu.com/aistudio/datasetdetail/120534 \n",
    "\n",
    "八类化妆品分别是 ['bbCream', 'blush', 'eyebrow', 'eyeshadow', 'foundation', 'lipstick', 'mascara', 'nail_polish']\n",
    "\n",
    "有训练数据集和测试数据集两类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、模型介绍\n",
    "\n",
    "整体项目构建如下，先从数据准备开始，使用到模型时候会介绍的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/6734476c8d4a426a991c6bcef20dca4126e2dcbae7d847bead6168c07768a900)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 引入os库,方便路径操作\n",
    "import os\n",
    "# 引入文件操作模块\n",
    "import shutil\n",
    "# 引入百度paddle模块\n",
    "import paddle as paddle\n",
    "# 引入百度飞桨的fluid模块,方便\n",
    "import paddle.fluid as fluid\n",
    "# 方便设置参数\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "# 引入自行封装的reader文件\n",
    "import work.keen_reader\n",
    "# 引入numpy库,方便计算和保存数据\n",
    "import numpy as np\n",
    "# 引入pandas库,方便使用\n",
    "import pandas as pd\n",
    "# 引入随机数\n",
    "import random\n",
    "# 引入日志库,方便记录操作的结果\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inflating: XSPLITED                \r"
     ]
    }
   ],
   "source": [
    "\r\n",
    "\"\"\"注意！！！\r\n",
    "\r\n",
    "该命令只需运行一次\r\n",
    "\r\n",
    "该行命令用于解压缩\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "# 获取预训练模型\r\n",
    "!wget http://paddle-imagenet-models-name.bj.bcebos.com/ResNet101_pretrained.tar\r\n",
    "!tar -xvf ResNet101_pretrained.tar\r\n",
    "#解压数据集图片\r\n",
    "!unzip data/data40449/D0001.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 配置超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tips:在这里配置主要修改的参数,在下面就用变量的方式来调用这些超参即可\r\n",
    "\r\n",
    "train_core1 = { \r\n",
    "    # 输入size大小,建议保持一致\r\n",
    "    \"input_size\": [3, 224, 224], \r\n",
    "    # 使用这个项目是要把目标图像分成多少种类\r\n",
    "    \"class_dim\":8,  # 分类数,\r\n",
    "    # 主要修改的超参学习率,可以试试0.001,0.005,0.01,0.02之类的，调节正确率波动\r\n",
    "    \"learning_rate\":0.002,\r\n",
    "    # 建议使用GPU,否则训练时间会很长\r\n",
    "    \"use_gpu\": True,\r\n",
    "    # 前期的训练轮数,你可以尝试着去增加试试看\r\n",
    "    \"num_epochs\": 30, #训练轮数\r\n",
    "    # 当达到想要的准确率就立刻保存下来当时的模型\r\n",
    "    \"last_acc\":0.4\r\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 初始化日志文件\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4b657823d8e0476a9b1a202d4dc98665a8dd29c623db409dbd21e6085d2b092f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 23:57:34,002-INFO: {'input_size': [3, 224, 224], 'class_dim': 8, 'learning_rate': 0.002, 'use_gpu': True, 'num_epochs': 30, 'last_acc': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# 设置一个全局的日志变量\r\n",
    "global logger \r\n",
    "logger = logging.getLogger() \r\n",
    "logger.setLevel(logging.INFO) \r\n",
    "log_path = os.path.join(os.getcwd(), 'logs') #当前目录下创建log文件夹\r\n",
    "if not os.path.exists(log_path): \r\n",
    "    os.makedirs(log_path) \r\n",
    "log_name = os.path.join(log_path, 'train.log') #日志文件的名字\r\n",
    "# sh = logging.StreamHandler() \r\n",
    "fh = logging.FileHandler(log_name, mode='w') \r\n",
    "fh.setLevel(logging.DEBUG) \r\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\") \r\n",
    "fh.setFormatter(formatter) \r\n",
    "# sh.setFormatter(formatter) \r\n",
    "# logger.addHandler(sh) \r\n",
    "logger.addHandler(fh) \r\n",
    "# 记录此次运行的超参,方便日后做记录进行比对\r\n",
    "logger.info(train_core1)\r\n",
    "\r\n",
    "# tips:小伙伴们可以在这里初始化日志的时候加上日期,更为方便."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据采集与预处理\n",
    "\n",
    "本次研究的对象为化妆品，使用的数据来源于百度官方提供的化妆品-8种分类数据集包含有8种不同化妆品的图片\n",
    "\n",
    "\n",
    "\n",
    "应用留出法，随机将90%的样本设置为训练集，10%的样本设置为测试集。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#按比例随机切割数据集\r\n",
    "train_ratio=0.90\r\n",
    "\r\n",
    "#tips: 小伙伴们可以在这里修改训练集和测试集的比例,比如0.5,0.7,0.9,比例越高效果相对来说较好\r\n",
    "\r\n",
    "train=open('train_split_list.txt','w')\r\n",
    "val=open('val_split_list.txt','w')\r\n",
    "with open('train_list.txt','r') as f:\r\n",
    "    #with open('data_sets/cat_12/train_split_list.txt','w+') as train:\r\n",
    "    lines=f.readlines()\r\n",
    "    for line in lines:\r\n",
    "        line=line.replace(\"\\\\\",\"/\")\r\n",
    "        line=line.replace(\" \",\"\\t\")\r\n",
    "        train.write(line)\r\n",
    "with open('val_list.txt','r') as f:\r\n",
    "    lines=f.readlines()\r\n",
    "    for line in lines:\r\n",
    "        line=line.replace(\"\\\\\",\"/\")\r\n",
    "        line=line.replace(\" \",\"\\t\")\r\n",
    "        val.write(line)\r\n",
    "\r\n",
    "train.close()\r\n",
    "val.close()\r\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "为了增加训练集的数据量，提高模型的泛化能力，对训练集进行数据增强处理\n",
    "\n",
    "应用数据增强技术，对已有图片做缩放、随机旋转、随机裁剪、对比度调整、色调调整以及饱和度调整，数据增强后，大幅提升了训练样本数量。\n",
    "\n",
    "为了之后的使用方便,进行了封装\n",
    "\n",
    "对输入的图片进行归一化，保证输入的信息类型一致。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 23:59:45,362-INFO: 成功加载数据\n"
     ]
    }
   ],
   "source": [
    "# tips:因为我已经封装成为文件了,你可以仔细读读work/keen_reader.py文件的\r\n",
    "\r\n",
    "##获取数据（batch_size可以调一次多少张）\r\n",
    "train_reader = paddle.batch(work.keen_reader.train(), batch_size=30)\r\n",
    "test_reader = paddle.batch(work.keen_reader.val(), batch_size=32)\r\n",
    "logger.info(\"成功加载数据\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# tips:解除注释,可以查看一下获得的数据是什么样子的\r\n",
    "# sampledata=next(train_reader())\r\n",
    "# print(sampledata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 迁移学习介绍\n",
    "\n",
    "在本次研究中，为保证ResNet101神经网络模型的泛化能力，采取迁移学习策略。\n",
    "\n",
    "采用两步化方案：第一步是预训练过程，首先，为阻止全连接层进行反向传播，去除最后一层全连接层,冻结整个整个卷积神经网络，\n",
    "返回进行卷积后的结果再依赖其构建一个分类为12层的全连接层，卷积神经网络载入官方的预训练模型。\n",
    "接着，使用AdamOptimizer优化器以较小的学习率与训练数据规模，对训练集进行尝试性的训练。在完成预训练后，保存新的分类器参数。\n",
    "\n",
    "[百度飞桨模型库](https://www.paddlepaddle.org.cn/modelbasedetail/resnet)\n",
    "\n",
    "[PaddlePaddle预训练模型](https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/README.md)\n",
    "\n",
    "(http://www.clzly.xyz/2020/python/bf62f4ed/%E5%9F%BA%E4%BA%8E%E7%BD%91%E7%BB%9C%E7%9A%84%E6%B7%B1%E5%BA%A6%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg)\n",
    "\n",
    "第二步，加载新分类器参数，开放全连接层上层的卷积神经网络部分，允许训练过程中从全连接层到网络浅层的反向传播。\n",
    "接着，使用SGD优化器以较小的学习率和较大的训练数据规模对模型进行最后的调试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义残差网络\n",
    "\n",
    "[论文](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "[ResNet论文翻译——中文版](http://noahsnail.com/2017/07/31/2017-07-31-ResNet%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E6%96%87%E7%89%88/)\n",
    "\n",
    "传统的卷积层或全连接层在传递信息时，或多或少会存在信息丢失、损耗等问题。ResNet在某种程度上解决了这个问题，通过直接将输入信息绕道传到输出，保护信息的完整性，整个网络只需要学习输入、输出差别的那一部分，简化学习目标和难度。\n",
    "\n",
    "作者将bottleneck拆分成多个分支，提出了神经网络中的第三个维度（另外两个维度分别为depth，神经网络层数深度，width，宽度，channel数），命名为`Cardinality`，并在多个数据集中证明了将bottleneck拆分能够降低训练错误率和提高准确率。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3b47cf39969547b4bfd67eb6a1303dd8bc42b9e301a346b1ab7171ab2b9e8df0)\n",
    "\n",
    "\n",
    "再看一下VGG19，一个34层深的普通卷积网络和34层深的ResNet网络的对比图。可以看到普通直连的卷积网络和ResNet的最大区别在于，ResNet有很多旁路的支线将输入直接连到后面的层，使得后面的层可以直接学习残差，这种结构也被称为shortcut或skip connections。\n",
    "\n",
    "<img src=\"http://noahsnail.com/images/resnet/Figure_3.jpeg\" width = \"100%\" align=\"center\" />\n",
    "\n",
    "\n",
    "图像分类模型架构，详见[百度飞桨官方的Github\n",
    "ResNet101](https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleCV/image_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resnet(input):\r\n",
    "    def conv_bn_layer(input, num_filters, filter_size, stride=1, groups=1, act=None, name=None):\r\n",
    "        conv = fluid.layers.conv2d(input=input,\r\n",
    "                                   num_filters=num_filters,\r\n",
    "                                   filter_size=filter_size,\r\n",
    "                                   stride=stride,\r\n",
    "                                   padding=(filter_size - 1) // 2,\r\n",
    "                                   groups=groups,\r\n",
    "                                   act=None,\r\n",
    "                                   param_attr=ParamAttr(name=name + \"_weights\"),\r\n",
    "                                   bias_attr=False,\r\n",
    "                                   name=name + '.conv2d.output.1')\r\n",
    "        if name == \"conv1\":\r\n",
    "            bn_name = \"bn_\" + name\r\n",
    "        else:\r\n",
    "            bn_name = \"bn\" + name[3:]\r\n",
    "        return fluid.layers.batch_norm(input=conv,\r\n",
    "                                       act=act,\r\n",
    "                                       name=bn_name + '.output.1',\r\n",
    "                                       param_attr=ParamAttr(name=bn_name + '_scale'),\r\n",
    "                                       bias_attr=ParamAttr(bn_name + '_offset'),\r\n",
    "                                       moving_mean_name=bn_name + '_mean',\r\n",
    "                                       moving_variance_name=bn_name + '_variance', )\r\n",
    "\r\n",
    "    def shortcut(input, ch_out, stride, name):\r\n",
    "        ch_in = input.shape[1]\r\n",
    "        if ch_in != ch_out or stride != 1:\r\n",
    "            return conv_bn_layer(input, ch_out, 1, stride, name=name)\r\n",
    "        else:\r\n",
    "            return input\r\n",
    "            \r\n",
    "    def bottleneck_block(input, num_filters, stride, name):\r\n",
    "        conv0 = conv_bn_layer(input=input,\r\n",
    "                              num_filters=num_filters,\r\n",
    "                              filter_size=1,\r\n",
    "                              act='relu',\r\n",
    "                              name=name + \"_branch2a\")\r\n",
    "        conv1 = conv_bn_layer(input=conv0,\r\n",
    "                              num_filters=num_filters,\r\n",
    "                              filter_size=3,\r\n",
    "                              stride=stride,\r\n",
    "                              act='relu',\r\n",
    "                              name=name + \"_branch2b\")\r\n",
    "        conv2 = conv_bn_layer(input=conv1,\r\n",
    "                              num_filters=num_filters * 4,\r\n",
    "                              filter_size=1,\r\n",
    "                              act=None,\r\n",
    "                              name=name + \"_branch2c\")\r\n",
    "\r\n",
    "        short = shortcut(input, num_filters * 4, stride, name=name + \"_branch1\")\r\n",
    "\r\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu', name=name + \".add.output.5\")\r\n",
    "\r\n",
    "    depth = [3, 4, 23, 3]\r\n",
    "    num_filters = [64, 128, 256, 512]\r\n",
    "\r\n",
    "    conv = conv_bn_layer(input=input, num_filters=64, filter_size=7, stride=2, act='relu', name=\"conv1\")\r\n",
    "    conv = fluid.layers.pool2d(input=conv, pool_size=3, pool_stride=2, pool_padding=1, pool_type='max')\r\n",
    "\r\n",
    "    for block in range(len(depth)):\r\n",
    "        for i in range(depth[block]):\r\n",
    "            if block == 2:\r\n",
    "                if i == 0:\r\n",
    "                    conv_name=\"res\"+str(block+2)+\"a\"\r\n",
    "                else:\r\n",
    "                    conv_name=\"res\"+str(block+2)+\"b\"+str(i)\r\n",
    "            else:\r\n",
    "                    conv_name=\"res\"+str(block+2)+chr(97+i)\r\n",
    "            conv = bottleneck_block(input=conv,\r\n",
    "                                    num_filters=num_filters[block],\r\n",
    "                                    stride=2 if i == 0 and block != 0 else 1,\r\n",
    "                                    name=conv_name)\r\n",
    "\r\n",
    "    pool = fluid.layers.pool2d(input=conv, pool_size=7, pool_type='avg', global_pooling=True)\r\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义输入层、主程序、损失函数和准确率函数、优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0218 23:59:55.985728  1499 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\n",
      "W0218 23:59:55.991214  1499 device_context.cc:245] device: 0, cuDNN Version: 7.6.\n",
      "2022-02-18 23:59:57,904-INFO: 成功参数初始化\n"
     ]
    }
   ],
   "source": [
    "##定义输入层\r\n",
    "image=fluid.layers.data(name='image',shape=train_core1[\"input_size\"],dtype='float32')\r\n",
    "label=fluid.layers.data(name='label',shape=[1],dtype='int64')\r\n",
    "\r\n",
    "\r\n",
    "##停止梯度下降（冻结网络层stop）\r\n",
    "pool=resnet(image)\r\n",
    "pool.stop_gradient=True\r\n",
    "\r\n",
    "##创建主程序来预训练\r\n",
    "base_model_program=fluid.default_main_program().clone()\r\n",
    "model=fluid.layers.fc(input=pool,size=train_core1[\"class_dim\"],act='softmax')\r\n",
    "\r\n",
    "\r\n",
    "##定义损失函数和准确率函数\r\n",
    "cost=fluid.layers.cross_entropy(input=model,label=label)\r\n",
    "avg_cost=fluid.layers.mean(cost)\r\n",
    "acc=fluid.layers.accuracy(input=model,label=label)\r\n",
    "\r\n",
    "\r\n",
    "##定义优化方法\r\n",
    "optimizer=fluid.optimizer.AdamOptimizer(learning_rate=train_core1[\"learning_rate\"])\r\n",
    "opts=optimizer.minimize(avg_cost)\r\n",
    "\r\n",
    "# tips:优化方法并不是只有Adam的,还有许多其他的方法,各有优劣,建议多加尝试\r\n",
    "\r\n",
    "##定义训练场所\r\n",
    "use_gpu=train_core1[\"use_gpu\"]\r\n",
    "place=fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\r\n",
    "exe=fluid.Executor(place)\r\n",
    "\r\n",
    "##进行参数初始化\r\n",
    "exe.run(fluid.default_startup_program())\r\n",
    "logger.info(\"成功参数初始化\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:00:35,510-INFO: 开始加载预训练模型\n",
      "2022-02-19 00:00:35,945-INFO: 加载预训练模型成功\n"
     ]
    }
   ],
   "source": [
    "#每次重启后运行一次\r\n",
    "##预训练模型路径\r\n",
    "src_pretrain_model_path='ResNet101_pretrained'\r\n",
    "logger.info(\"开始加载预训练模型\") \r\n",
    "##判断模型文件是否存在\r\n",
    "def if_exit(var):\r\n",
    "    path=os.path.join(src_pretrain_model_path,var.name)\r\n",
    "    exist=os.path.exists(path)\r\n",
    "    if exist:\r\n",
    "      # print('Load model: %s' % path)\r\n",
    "      return exist\r\n",
    "\r\n",
    "##加载模型文件，且只加载存在模型的模型文件\r\n",
    "fluid.io.load_vars(executor=exe,dirname=src_pretrain_model_path,predicate=if_exit,main_program=base_model_program)\r\n",
    "logger.info(\"加载预训练模型成功\") \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义数据维度并开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:00:38,958-INFO: 开始第一批训练数据。。。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:2.57365, Accuracy:0.20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:00:43,087-INFO: 临时保存第0批次的训练结果，准确率为[0.41666666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:1, Batch:0, Cost:1.12490, Accuracy:0.56667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:00:47,534-INFO: 临时保存第1批次的训练结果，准确率为[0.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:2, Batch:0, Cost:0.49003, Accuracy:0.86667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:00:52,377-INFO: 临时保存第2批次的训练结果，准确率为[0.9166667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:3, Batch:0, Cost:0.71967, Accuracy:0.76667\n",
      "Pass:4, Batch:0, Cost:0.74525, Accuracy:0.80000\n",
      "Pass:5, Batch:0, Cost:0.50301, Accuracy:0.83333\n",
      "Pass:6, Batch:0, Cost:0.53071, Accuracy:0.83333\n",
      "Pass:7, Batch:0, Cost:0.40639, Accuracy:0.93333\n",
      "Pass:8, Batch:0, Cost:0.43885, Accuracy:0.80000\n",
      "Pass:9, Batch:0, Cost:0.48020, Accuracy:0.80000\n",
      "Pass:10, Batch:0, Cost:0.42693, Accuracy:0.86667\n",
      "Pass:11, Batch:0, Cost:0.59132, Accuracy:0.73333\n",
      "Pass:12, Batch:0, Cost:0.95407, Accuracy:0.56667\n",
      "Pass:13, Batch:0, Cost:0.80894, Accuracy:0.70000\n",
      "Pass:14, Batch:0, Cost:0.37398, Accuracy:0.83333\n",
      "Pass:15, Batch:0, Cost:0.83668, Accuracy:0.70000\n",
      "Pass:16, Batch:0, Cost:0.35092, Accuracy:0.90000\n",
      "Pass:17, Batch:0, Cost:0.68283, Accuracy:0.73333\n",
      "Pass:18, Batch:0, Cost:0.48504, Accuracy:0.83333\n",
      "Pass:19, Batch:0, Cost:1.06601, Accuracy:0.63333\n",
      "Pass:20, Batch:0, Cost:0.59260, Accuracy:0.73333\n",
      "Pass:21, Batch:0, Cost:0.43254, Accuracy:0.80000\n",
      "Pass:22, Batch:0, Cost:0.50861, Accuracy:0.83333\n",
      "Pass:23, Batch:0, Cost:0.35110, Accuracy:0.86667\n",
      "Pass:24, Batch:0, Cost:0.42785, Accuracy:0.86667\n",
      "Pass:25, Batch:0, Cost:0.59883, Accuracy:0.73333\n",
      "Pass:26, Batch:0, Cost:0.36631, Accuracy:0.86667\n",
      "Pass:27, Batch:0, Cost:1.07704, Accuracy:0.76667\n",
      "Pass:28, Batch:0, Cost:0.50922, Accuracy:0.76667\n",
      "Pass:29, Batch:0, Cost:0.33331, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:02:39,011-INFO: 第一批训练数据结束。\n"
     ]
    }
   ],
   "source": [
    "##定义数据维度\r\n",
    "feeder=fluid.DataFeeder(place=place,feed_list=[image,label])\r\n",
    "save_pretrain_model_path='models/step-1_model/'\r\n",
    "# 预期的准确率\r\n",
    "last_acc=train_core1[\"last_acc\"]\r\n",
    "# 初始的准确率\r\n",
    "now_acc=0\r\n",
    "logger.info(\"开始第一批训练数据。。。\") \r\n",
    "for pass_id in range(train_core1[\"num_epochs\"]):\r\n",
    "    for batch_id,data in enumerate(train_reader()):\r\n",
    "        train_cost,train_acc=exe.run(program = fluid.default_main_program(),feed=feeder.feed(data),fetch_list=[avg_cost,acc])\r\n",
    "        if batch_id%50==0:\r\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\r\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))\r\n",
    "    \r\n",
    "    now_acc=train_acc\r\n",
    "    if now_acc>last_acc and now_acc!=1:\r\n",
    "        last_acc=now_acc\r\n",
    "        logger.info(\"临时保存第{0}批次的训练结果，准确率为{1}\".format(pass_id,now_acc)) \r\n",
    "        ##删除旧的模型文件\r\n",
    "        shutil.rmtree(save_pretrain_model_path,ignore_errors=True)\r\n",
    "        ##创建保存模型文件记录\r\n",
    "        os.makedirs(save_pretrain_model_path)\r\n",
    "        ##保存参数模型\r\n",
    "        fluid.io.save_params(executor=exe,dirname=save_pretrain_model_path)\r\n",
    "logger.info(\"第一批训练数据结束。\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  **Step-2**\n",
    "\n",
    "此处需要重启环境，否则会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 此处同上\r\n",
    "import os\r\n",
    "import shutil\r\n",
    "import paddle as paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from paddle.fluid.param_attr import ParamAttr\r\n",
    "import work.keen_reader\r\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_core2 = { \r\n",
    "    \"input_size\": [3, 224, 224], \r\n",
    "    \"class_dim\": 8,  # 分类数,\r\n",
    "    # 定义学习率,这里也是可以多加修改的\r\n",
    "    \"learning_rate\":0.002,\r\n",
    "    # 定义sgd的学习率\r\n",
    "    \"sgd_learning_rate\":0.0002,\r\n",
    "    # 学习率自调整\r\n",
    "    \"lrepochs\":[20,40,60,80,100],\r\n",
    "    \"lrdecay\":[1,0.5,0.25,0.1,0.01,0.002],\r\n",
    "    \"use_gpu\": True,\r\n",
    "    # 这里的训练轮数自我把握,因为在后期可能训练500轮在最后的200轮已经没有变化了\r\n",
    "    \"num_epochs\": 30, #训练轮数\r\n",
    "    # 想要达到的最终准确率\r\n",
    "    \"last_acc\":0.7\r\n",
    "\r\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 初始化日志文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:06:39,962-INFO: train_core2 config: {'input_size': [3, 224, 224], 'class_dim': 8, 'learning_rate': 0.002, 'sgd_learning_rate': 0.0002, 'lrepochs': [20, 40, 60, 80, 100], 'lrdecay': [1, 0.5, 0.25, 0.1, 0.01, 0.002], 'use_gpu': True, 'num_epochs': 30, 'last_acc': 0.7}\n"
     ]
    }
   ],
   "source": [
    "#初始化日志文件\r\n",
    "\r\n",
    "global logger \r\n",
    "logger = logging.getLogger() \r\n",
    "logger.setLevel(logging.INFO) \r\n",
    "log_path = os.path.join(os.getcwd(), 'logs') #当前目录下创建log文件夹\r\n",
    "if not os.path.exists(log_path): \r\n",
    "    os.makedirs(log_path) \r\n",
    "log_name = os.path.join(log_path, 'test.log') #日志文件的名字\r\n",
    "# sh = logging.StreamHandler() \r\n",
    "fh = logging.FileHandler(log_name, mode='w') \r\n",
    "fh.setLevel(logging.DEBUG) \r\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\") \r\n",
    "fh.setFormatter(formatter) \r\n",
    "# sh.setFormatter(formatter) \r\n",
    "# logger.addHandler(sh) \r\n",
    "logger.addHandler(fh) \r\n",
    "\r\n",
    "logger.info(\"train_core2 config: %s\", str(train_core2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 加载数据信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:06:43,549-INFO: 成功加载数据\n"
     ]
    }
   ],
   "source": [
    "##获取数据\r\n",
    "train_reader = paddle.batch(work.keen_reader.train(), batch_size=30)\r\n",
    "test_reader = paddle.batch(work.keen_reader.val(), batch_size=32)\r\n",
    "logger.info(\"成功加载数据\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义新的残差网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tips: 新定义resnet，加上fc\r\n",
    "def resnet(input,class_dim):\r\n",
    "    def conv_bn_layer(input, num_filters, filter_size, stride=1, groups=1, act=None, name=None):\r\n",
    "        conv = fluid.layers.conv2d(input=input,\r\n",
    "                                   num_filters=num_filters,\r\n",
    "                                   filter_size=filter_size,\r\n",
    "                                   stride=stride,\r\n",
    "                                   padding=(filter_size - 1) // 2,\r\n",
    "                                   groups=groups,\r\n",
    "                                   act=None,\r\n",
    "                                   param_attr=ParamAttr(name=name + \"_weights\"),\r\n",
    "                                   bias_attr=False,\r\n",
    "                                   name=name + '.conv2d.output.1')\r\n",
    "        if name == \"conv1\":\r\n",
    "            bn_name = \"bn_\" + name\r\n",
    "        else:\r\n",
    "            bn_name = \"bn\" + name[3:]\r\n",
    "        return fluid.layers.batch_norm(input=conv,\r\n",
    "                                       act=act,\r\n",
    "                                       name=bn_name + '.output.1',\r\n",
    "                                       param_attr=ParamAttr(name=bn_name + '_scale'),\r\n",
    "                                       bias_attr=ParamAttr(bn_name + '_offset'),\r\n",
    "                                       moving_mean_name=bn_name + '_mean',\r\n",
    "                                       moving_variance_name=bn_name + '_variance', )\r\n",
    "\r\n",
    "    def shortcut(input, ch_out, stride, name):\r\n",
    "        ch_in = input.shape[1]\r\n",
    "        if ch_in != ch_out or stride != 1:\r\n",
    "            return conv_bn_layer(input, ch_out, 1, stride, name=name)\r\n",
    "        else:\r\n",
    "            return input\r\n",
    "            \r\n",
    "    def bottleneck_block(input, num_filters, stride, name):\r\n",
    "        conv0 = conv_bn_layer(input=input,\r\n",
    "                              num_filters=num_filters,\r\n",
    "                              filter_size=1,\r\n",
    "                              act='relu',\r\n",
    "                              name=name + \"_branch2a\")\r\n",
    "        conv1 = conv_bn_layer(input=conv0,\r\n",
    "                              num_filters=num_filters,\r\n",
    "                              filter_size=3,\r\n",
    "                              stride=stride,\r\n",
    "                              act='relu',\r\n",
    "                              name=name + \"_branch2b\")\r\n",
    "        conv2 = conv_bn_layer(input=conv1,\r\n",
    "                              num_filters=num_filters * 4,\r\n",
    "                              filter_size=1,\r\n",
    "                              act=None,\r\n",
    "                              name=name + \"_branch2c\")\r\n",
    "\r\n",
    "        short = shortcut(input, num_filters * 4, stride, name=name + \"_branch1\")\r\n",
    "\r\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu', name=name + \".add.output.5\")\r\n",
    "\r\n",
    "    depth = [3, 4, 23, 3]\r\n",
    "    num_filters = [64, 128, 256, 512]\r\n",
    "\r\n",
    "    conv = conv_bn_layer(input=input, num_filters=64, filter_size=7, stride=2, act='relu', name=\"conv1\")\r\n",
    "    conv = fluid.layers.pool2d(input=conv, pool_size=3, pool_stride=2, pool_padding=1, pool_type='max')\r\n",
    "\r\n",
    "    for block in range(len(depth)):\r\n",
    "        for i in range(depth[block]):\r\n",
    "            if block == 2:\r\n",
    "                if i == 0:\r\n",
    "                    conv_name=\"res\"+str(block+2)+\"a\"\r\n",
    "                else:\r\n",
    "                    conv_name=\"res\"+str(block+2)+\"b\"+str(i)\r\n",
    "            else:\r\n",
    "                    conv_name=\"res\"+str(block+2)+chr(97+i)\r\n",
    "            conv = bottleneck_block(input=conv,\r\n",
    "                                    num_filters=num_filters[block],\r\n",
    "                                    stride=2 if i == 0 and block != 0 else 1,\r\n",
    "                                    name=conv_name)\r\n",
    "\r\n",
    "    pool = fluid.layers.pool2d(input=conv, pool_size=7, pool_type='avg', global_pooling=True)\r\n",
    "    output=fluid.layers.fc(input=pool,size=class_dim,act='softmax')#全连接层不冻结，全参与\r\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义输入层、主程序、损失函数和准确率函数、优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:06:50,180-INFO: 成功定义输入层\n",
      "W0219 00:06:52.601284  2705 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\n",
      "W0219 00:06:52.606911  2705 device_context.cc:245] device: 0, cuDNN Version: 7.6.\n",
      "2022-02-19 00:06:54,546-INFO: 成功进行参数初始化\n"
     ]
    }
   ],
   "source": [
    "##定义输入层\r\n",
    "image = fluid.layers.data(name='image', shape=train_core2[\"input_size\"], dtype='float32')\r\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')\r\n",
    "logger.info(\"成功定义输入层\") \r\n",
    "##获取分类器\r\n",
    "model = resnet(image,train_core2[\"class_dim\"])\r\n",
    "\r\n",
    "##获取损失函数和准确率函数\r\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)\r\n",
    "avg_cost = fluid.layers.mean(cost)\r\n",
    "acc = fluid.layers.accuracy(input=model, label=label)\r\n",
    "\r\n",
    "##获取训练和测试程序\r\n",
    "test_program = fluid.default_main_program().clone(for_test=True)\r\n",
    "\r\n",
    "##定义优化方法\r\n",
    "optimizer=fluid.optimizer.SGD(learning_rate=train_core2[\"sgd_learning_rate\"])\r\n",
    "opts=optimizer.minimize(avg_cost)\r\n",
    "\r\n",
    "# tips:不同的优化方法都可以多加尝试,尤其是第一步和第二步优化方法相同或者不同都会有\"惊\"\"喜\"哦!\r\n",
    "\r\n",
    "##定义一个使用GPU的执行器\r\n",
    "use_gpu=train_core2[\"use_gpu\"]\r\n",
    "place=fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\r\n",
    "exe=fluid.Executor(place)\r\n",
    "\r\n",
    "##进行参数初始化\r\n",
    "exe.run(fluid.default_startup_program())\r\n",
    "logger.info(\"成功进行参数初始化\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 加载经过处理的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 00:07:01,171-INFO: 成功加载第一步的预训练模型！\n"
     ]
    }
   ],
   "source": [
    "##经过step-1处理后的的预训练模型\r\n",
    "pretrained_model_path = 'models/step-1_model/'\r\n",
    "\r\n",
    "##加载经过处理的模型\r\n",
    "fluid.io.load_params(executor=exe, dirname=pretrained_model_path)\r\n",
    "last_acc=train_core2[\"last_acc\"]\r\n",
    "logger.info(\"成功加载第一步的预训练模型！\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from visualdl import LogWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义数据维度并开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:50:50,177-INFO: 开始第二批训练数据。。。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:0.35287, Accuracy:0.80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:50:58,278-INFO: Test:0, Cost:0.38565, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:1, Batch:0, Cost:0.26092, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:51:06,329-INFO: Test:1, Cost:0.39537, Accuracy:0.87946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:2, Batch:0, Cost:0.30529, Accuracy:0.86667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:51:14,666-INFO: Test:2, Cost:0.38622, Accuracy:0.85268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:3, Batch:0, Cost:0.15349, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:51:23,180-INFO: Test:3, Cost:0.40253, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:4, Batch:0, Cost:0.31671, Accuracy:0.90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:51:31,440-INFO: Test:4, Cost:0.40879, Accuracy:0.86161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:5, Batch:0, Cost:0.28207, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:51:39,389-INFO: Test:5, Cost:0.39135, Accuracy:0.87946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:6, Batch:0, Cost:0.15747, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:51:47,570-INFO: Test:6, Cost:0.39269, Accuracy:0.88393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:7, Batch:0, Cost:0.31525, Accuracy:0.90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:51:55,826-INFO: Test:7, Cost:0.39779, Accuracy:0.83929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:8, Batch:0, Cost:0.22313, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:52:03,802-INFO: Test:8, Cost:0.39181, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:9, Batch:0, Cost:0.13410, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:52:11,941-INFO: Test:9, Cost:0.41044, Accuracy:0.86161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:10, Batch:0, Cost:0.07096, Accuracy:1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:52:20,381-INFO: Test:10, Cost:0.39549, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:11, Batch:0, Cost:0.41705, Accuracy:0.86667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:52:28,342-INFO: Test:11, Cost:0.39592, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:12, Batch:0, Cost:0.23764, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:52:36,667-INFO: Test:12, Cost:0.39826, Accuracy:0.86161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:13, Batch:0, Cost:0.14142, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:52:45,016-INFO: Test:13, Cost:0.40567, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:14, Batch:0, Cost:0.31687, Accuracy:0.90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:52:53,282-INFO: Test:14, Cost:0.40179, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:15, Batch:0, Cost:0.17798, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:53:01,296-INFO: Test:15, Cost:0.40946, Accuracy:0.85268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:16, Batch:0, Cost:0.43305, Accuracy:0.90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:53:09,967-INFO: Test:16, Cost:0.41472, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:17, Batch:0, Cost:0.25062, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:53:18,256-INFO: Test:17, Cost:0.39409, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:18, Batch:0, Cost:0.21505, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:53:26,075-INFO: Test:18, Cost:0.40421, Accuracy:0.85268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:19, Batch:0, Cost:0.21261, Accuracy:0.90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:53:34,270-INFO: Test:19, Cost:0.41062, Accuracy:0.85268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:20, Batch:0, Cost:0.17190, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:53:42,377-INFO: Test:20, Cost:0.40133, Accuracy:0.85268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:21, Batch:0, Cost:0.15603, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:53:50,288-INFO: Test:21, Cost:0.39475, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:22, Batch:0, Cost:0.20223, Accuracy:0.90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:53:58,509-INFO: Test:22, Cost:0.40050, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:23, Batch:0, Cost:0.14945, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:54:06,864-INFO: Test:23, Cost:0.39314, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:24, Batch:0, Cost:0.16549, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:54:15,202-INFO: Test:24, Cost:0.40673, Accuracy:0.85268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:25, Batch:0, Cost:0.30344, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:54:23,178-INFO: Test:25, Cost:0.39319, Accuracy:0.86161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:26, Batch:0, Cost:0.14175, Accuracy:1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:54:31,419-INFO: Test:26, Cost:0.40248, Accuracy:0.85268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:27, Batch:0, Cost:0.48915, Accuracy:0.90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:54:39,642-INFO: Test:27, Cost:0.39791, Accuracy:0.85268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:28, Batch:0, Cost:0.30502, Accuracy:0.93333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:54:47,532-INFO: Test:28, Cost:0.39055, Accuracy:0.85714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:29, Batch:0, Cost:0.15431, Accuracy:0.96667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 01:54:55,815-INFO: Test:29, Cost:0.40511, Accuracy:0.85714\n",
      "2022-02-19 01:54:55,817-INFO: 第二批训练数据结束。\n"
     ]
    }
   ],
   "source": [
    "##定义数据维度\r\n",
    "feeder=fluid.DataFeeder(place=place,feed_list=[image,label])\r\n",
    "#value = [i/1000.0 for i in range(1000)]\r\n",
    "now_acc=0\r\n",
    "logger.info(\"开始第二批训练数据。。。\") \r\n",
    "##保存预测模型\r\n",
    "save_path = 'models/step_2_model/'\r\n",
    "with LogWriter(logdir=\"./log/scalar_test/train\") as writer:\r\n",
    "    for pass_id in range(train_core2[\"num_epochs\"]):\r\n",
    "        ##训练\r\n",
    "        for batch_id,data in enumerate(train_reader()):\r\n",
    "            train_cost,train_acc=exe.run(program=fluid.default_main_program(),feed=feeder.feed(data),fetch_list=[avg_cost,acc])\r\n",
    "            if batch_id%50==0:\r\n",
    "                print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\r\n",
    "                    (pass_id, batch_id, train_cost[0], train_acc[0]))\r\n",
    "        ##测试\r\n",
    "        test_accs=[]\r\n",
    "        test_costs=[]\r\n",
    "        for batch_id,data in enumerate(test_reader()):\r\n",
    "            test_cost,test_acc=exe.run(program=test_program,feed=feeder.feed(data), fetch_list=[avg_cost,acc])\r\n",
    "            test_accs.append(test_acc[0])\r\n",
    "            test_costs.append(test_cost[0])\r\n",
    "        test_cost = (sum(test_costs) / len(test_costs))\r\n",
    "        test_acc = (sum(test_accs) / len(test_accs))\r\n",
    "        logger.info('Test:%d, Cost:%0.5f, Accuracy:%0.5f' % (pass_id, test_cost, test_acc))\r\n",
    "        writer.add_scalar(tag=\"acc\", step=pass_id, value=test_acc)\r\n",
    "        writer.add_scalar(tag=\"loss\", step=pass_id, value=test_cost)\r\n",
    "        now_acc=test_acc\r\n",
    "        \r\n",
    "        if now_acc>last_acc:\r\n",
    "            last_acc=now_acc\r\n",
    "            logger.info(\"临时保存第 {0}批次的训练结果，准确率为 acc1 {1}\".format(pass_id, now_acc))\r\n",
    "            \r\n",
    "            ##删除旧的模型文件\r\n",
    "            shutil.rmtree(save_path, ignore_errors=True)\r\n",
    "            ##创建保持模型文件目录\r\n",
    "            os.makedirs(save_path)\r\n",
    "            ##保存预测模型\r\n",
    "            fluid.io.save_inference_model(save_path, feeded_var_names=[image.name], target_vars=[model], executor=exe)\r\n",
    "    logger.info(\"第二批训练数据结束。\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五、模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 可视化acc结果和loss结果\n",
    "\n",
    "目前经典版的aistudio没有VisualDL的可视化了，所以是新建了一个BMLCodeLab里面进行可视化的\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f86a3c2b642a4377960dfd474ebda5f6fa225c177f3f41ea9c47f53172d3db43)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f99eee077ffa43cdb0d5ea79ad6904562992558bd7b04a0880688bf7cd4aa6e3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/d79074fe74044ac0bd4c33118236ddb46c67f2ec649348c0801fd7e2114676fc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setp3 生成预测结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "test_list_imagepath=[]\r\n",
    "test_list_labels=[]\r\n",
    "test_dict={}\r\n",
    "\r\n",
    "with open(\"./test_list.txt\") as f1:\r\n",
    "    for line1 in f1:\r\n",
    "        line1=line1.replace('\\\\','@')\r\n",
    "        line1=line1.replace('@','/')\r\n",
    "        test_list_imagepath.append(line1[:-3])\r\n",
    "        test_list_labels.append(line1[-2])\r\n",
    "        test_dict[line1[:-3]]=line1[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '6', '6', '0', '2', '4', '4', '4', '5', '7', '6', '4', '1', '1', '4', '1', '0', '4', '1', '4', '5', '7', '5', '6', '4', '4', '5', '2', '3', '1', '7', '0', '1', '6', '2', '0', '2', '7', '4', '7', '7', '2', '2', '4', '2', '2', '6', '3', '0', '0', '4', '5', '2', '6', '4', '5', '4', '7', '6', '2', '0', '2', '1', '1', '4', '4', '6', '4', '1', '2', '0', '2', '0', '1', '6', '2', '0', '6', '0', '4', '3', '3', '6', '0', '0', '4', '4', '5', '4', '1', '1', '5', '4', '7', '4', '1', '4', '4', '7', '4']\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "print(test_list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eyebrow/6_261.jpg', 'mascara/990.jpg', 'mascara/16.jpeg', 'bbCream/1591974297.4060996.jpg', 'eyebrow/6_52.jpg', 'foundation/1_82.jpg', 'foundation/386.png', 'foundation/1_143.jpg', 'lipstick/615.png', 'nail_polish/138.png', 'mascara/5_215.jpg', 'foundation/334.jpeg', 'blush/0_75.jpg', 'blush/1017.png', 'foundation/317.png', 'blush/0_104.jpg', 'bbCream/1591973804.2530024.jpg', 'foundation/1_5.jpg', 'blush/421.jpg', 'foundation/391.jpg', 'lipstick/873.jpg', 'nail_polish/93_2.jpg', 'lipstick/3_148.jpg', 'mascara/5_275.jpg', 'foundation/1_16.jpg', 'foundation/1_96.jpg', 'lipstick/516.jpg', 'eyebrow/6_248.jpg', 'eyeshadow/4_57.jpg', 'blush/0_136.jpg', 'nail_polish/142.jpg', 'bbCream/1591974298.7393937.jpg', 'blush/924.jpg', 'mascara/5_228.jpg', 'eyebrow/6_20.jpg', 'bbCream/1591974288.053845.jpg', 'eyebrow/6_213.jpg', 'nail_polish/104_2.jpg', 'foundation/1_73.jpg', 'nail_polish/103b_2.jpg', 'nail_polish/156.jpg', 'eyebrow/6_207.jpg', 'eyebrow/6_90.jpg', 'foundation/1_2.jpg', 'eyebrow/6_121.jpg', 'eyebrow/912.jpg', 'mascara/1025.png', 'eyeshadow/530.jpg', 'bbCream/1591974288.8068342.jpg', 'bbCream/1591974286.984704.jpg', 'foundation/342.jpeg', 'lipstick/877.jpg', 'eyebrow/6_62.jpg', 'mascara/5_18.jpg', 'foundation/1_80.jpg', 'lipstick/3_1.jpg', 'foundation/336.jpeg', 'nail_polish/144.jpg', 'mascara/48.jpg', 'eyebrow/6_102.jpg', 'bbCream/1591974298.1649284.jpg', 'eyebrow/1019.jpg', 'blush/920.jpg', 'blush/0_154.jpg', 'foundation/1_55.jpg', 'foundation/1_132.jpg', 'mascara/5_139.jpg', 'foundation/1_29.jpg', 'blush/0_183.jpg', 'eyebrow/6_94.jpg', 'bbCream/1591974294.1733775.jpg', 'eyebrow/6_6.jpg', 'bbCream/1591973806.808174.jpg', 'blush/0_169.jpg', 'mascara/5_175.jpg', 'eyebrow/553.jpg', 'bbCream/1591974288.474722.jpg', 'mascara/26.jpeg', 'bbCream/1591974288.1196697.jpg', 'foundation/1_64.jpg', 'eyeshadow/283.jpeg', 'eyeshadow/305.jpeg', 'mascara/8.jpeg', 'bbCream/1591974291.0613208.jpg', 'bbCream/1591974288.644268.jpg', 'foundation/1_101.jpg', 'foundation/899.jpg', 'lipstick/58.png', 'foundation/337.png', 'blush/414.png', 'blush/449.jpeg', 'lipstick/619.png', 'foundation/1_113.jpg', 'nail_polish/123.png', 'foundation/898.jpg', 'blush/0_37.jpg', 'foundation/1_135.jpg', 'foundation/1_36.jpg', 'nail_polish/121.jpg', 'foundation/897.jpg']\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "print(test_list_imagepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功输出结果文件\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SAVE_DIRNAME = './models/step_2_model'  # 保存好的 inference model 的路径\n",
    "abs_path = r'./' # 测试文件夹的真实路径\n",
    "#########################################################################\n",
    "# coding:utf-8\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import json\n",
    "\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "TOP_K = 1\n",
    "DATA_DIM = 224\n",
    "\n",
    "use_cuda = True\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model( SAVE_DIRNAME, exe\n",
    "                # model_filename='model',\n",
    "                # params_filename='params'\n",
    "                # model_filename = 'fc_0.w_0',\n",
    "                # params_filename = 'params'\n",
    "                )\n",
    "\n",
    "\n",
    "def real_infer_one_img(im):\n",
    "    infer_result = exe.run(\n",
    "        inference_program,\n",
    "        feed={feed_target_names[0]: im},\n",
    "        fetch_list=fetch_targets)\n",
    "\n",
    "    # print(infer_result)\n",
    "    # 打印预测结果\n",
    "    mini_batch_result = np.argsort(infer_result)  # 找出可能性最大的列标，升序排列\n",
    "    # print(mini_batch_result.shape)\n",
    "    mini_batch_result = mini_batch_result[0][:, -TOP_K:]  # 把这些列标拿出来\n",
    "    mini_batch_result = mini_batch_result.flatten() #拉平了，只吐出一个 array\n",
    "    mini_batch_result = mini_batch_result[::-1] #逆序\n",
    "    return mini_batch_result\n",
    "\n",
    "\n",
    "def resize_short(img, target_size):\n",
    "    percent = float(target_size) / min(img.size[0], img.size[1])\n",
    "    resized_width = int(round(img.size[0] * percent))\n",
    "    resized_height = int(round(img.size[1] * percent))\n",
    "    img = img.resize((resized_width, resized_height), Image.LANCZOS)\n",
    "    return img\n",
    "\n",
    "\n",
    "def crop_image(img, target_size, center):\n",
    "    width, height = img.size\n",
    "    size = target_size\n",
    "    if center == True:\n",
    "        w_start = (width - size) / 2\n",
    "        h_start = (height - size) / 2\n",
    "    else:\n",
    "        w_start = np.random.randint(0, width - size + 1)\n",
    "        h_start = np.random.randint(0, height - size + 1)\n",
    "    w_end = w_start + size\n",
    "    h_end = h_start + size\n",
    "    img = img.crop((w_start, h_start, w_end, h_end))\n",
    "    return img\n",
    "\n",
    "img_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "\n",
    "def process_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = resize_short(img, target_size=256)\n",
    "    img = crop_image(img, target_size=DATA_DIM, center=True)\n",
    "\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    img = np.array(img).astype(np.float32).transpose((2, 0, 1)) / 255\n",
    "    img -= img_mean\n",
    "    img /= img_std\n",
    "\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def convert_list(my_list):\n",
    "    my_list = list(my_list)\n",
    "    my_list = map(lambda x:str(x), my_list)\n",
    "    # print('_'.join(my_list))\n",
    "    return '_'.join(my_list)\n",
    "\n",
    "\n",
    "def infer(file_path):\n",
    "    im = process_image(file_path)\n",
    "    result = real_infer_one_img(im)\n",
    "    result = convert_list(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createCSVFile(cat_12_test_path,test_list_imagepath):\n",
    "    lines = []\n",
    "\n",
    "    # 获取所有的文件名\n",
    "    \n",
    "    for file_name in test_list_imagepath:\n",
    "        file_name = file_name\n",
    "        file_abs_path = os.path.join(cat_12_test_path, file_name)\n",
    "        result_classes = infer(file_abs_path)\n",
    "\n",
    "        file_predict_classes = result_classes\n",
    "\n",
    "        line = '%s,%s\\n'%(file_name, file_predict_classes)\n",
    "        lines.append(line)\n",
    "\n",
    "    with open('result.csv', 'w') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "\n",
    "createCSVFile(abs_path,test_list_imagepath)\n",
    "print(\"成功输出结果文件\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### models/step_2_model的结果与正确label的对比\n",
    "\n",
    "result的部分结果![](https://ai-studio-static-online.cdn.bcebos.com/519d55838593428e9f38a7ee66119c7e10380cd0428b42308239b731738841b8)，正确test_list.label![](https://ai-studio-static-online.cdn.bcebos.com/973eee1d8fc548d49070748db073ca5a1b59debd6b094c78a1fd627ae8e5e4be)\n",
    "\n",
    "大概是22个里面错了三个，其中foundation错误率比较高一点\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 六、个人小结\n",
    "\n",
    "经过几次测试，方法二的正确率远远高于方法一，炼丹之路还很长\n",
    "\n",
    "通过学习这个项目,我大概可以更进一步的掌握ResNet的网络的基础结构和迁移学习的应用\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 七、参考文献\n",
    "\n",
    "猫十二分类-飞桨图像分类帮我云撸猫（基于ResNet的图像分类）[https://aistudio.baidu.com/aistudio/projectdetail/474305?channel=0&channelType=0&shared=1](https://aistudio.baidu.com/aistudio/projectdetail/474305?channel=0&channelType=0&shared=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
